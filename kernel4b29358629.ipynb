{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.listdir(\"/kaggle/input/prefetch-data-final-2\")","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"['data_lbm.csv', 'data_sphinx3.csv', 'data_xalancbmk.csv']"},"metadata":{}}]},{"metadata":{"id":"5ot6fKDCFszs","outputId":"c1dd8d9a-8320-4fdf-fdd2-17e029d6f846","trusted":true},"cell_type":"code","source":"!pip install keras-self-attention","execution_count":5,"outputs":[{"output_type":"stream","text":"Collecting keras-self-attention\n  Downloading keras-self-attention-0.46.0.tar.gz (10 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from keras-self-attention) (1.18.1)\nRequirement already satisfied: Keras in /opt/conda/lib/python3.7/site-packages (from keras-self-attention) (2.3.1)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras->keras-self-attention) (2.10.0)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from Keras->keras-self-attention) (1.0.8)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from Keras->keras-self-attention) (5.3.1)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from Keras->keras-self-attention) (1.14.0)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from Keras->keras-self-attention) (1.4.1)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from Keras->keras-self-attention) (1.1.2)\nBuilding wheels for collected packages: keras-self-attention\n  Building wheel for keras-self-attention (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-py3-none-any.whl size=17278 sha256=3568bbb40e5241c58a6ff463d7e6364ed6b44a2f9712104b3e77814495b283e3\n  Stored in directory: /root/.cache/pip/wheels/ec/f7/48/30de93f8333298bad9202aab9b04db0cfd58dcd379b5a5ef1c\nSuccessfully built keras-self-attention\nInstalling collected packages: keras-self-attention\nSuccessfully installed keras-self-attention-0.46.0\n","name":"stdout"}]},{"metadata":{"id":"tfTUxsHRFrFu","trusted":true},"cell_type":"code","source":"import keras\nfrom keras_self_attention import SeqSelfAttention","execution_count":6,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"id":"bumPKVU-jbuS","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom nltk import ngrams\nfrom sklearn.preprocessing import MinMaxScaler\nfrom datetime import datetime\nimport tensorflow.keras.backend as K\nfrom keras.utils import to_categorical\nfrom collections import Counter\nimport json\n\n\nROOT_DIR = \"/kaggle/input/prefetch-data-final-2/\"\n\ndef get_memory_addr_line(line):\n    addr = 0\n    ip = 0\n    tokens = line.split(\"\\t\")\n    if len(tokens)==2:\n        try:\n            addr = int(tokens[1].strip())\n            ip = int(tokens[0].strip())\n        except:\n            print(\"Error parsing...\")\n            return 0, 0\n    return addr, ip\n\ndef get_sequence(col):\n    list1 = list(map(int, col.split(\",\")))\n    return list1\n\ndef parse_data(limit=50000):\n    data = pd.read_csv(ROOT_DIR + \"data_lbm.csv\", sep=\"\\t\")\n    print(data[:5])\n    data['ADDRS'] = data['ADDRS'].apply(get_sequence)\n    data['PCS'] = data['PCS'].apply(get_sequence)\n\n    addrs = []\n    PCs = []\n\n    for _, row in data.iterrows():\n        addrs.append(list(row.ADDRS))\n        PCs.append(list(row.PCS))\n\n    addrs = np.array(addrs)\n    PCs = np.array(PCs)\n    print(addrs.shape)\n    deltas = []\n    for i in range(addrs.shape[0]):\n        deltas.append(addrs[i,-1]-addrs[i,-2])\n    addrs = addrs[:,:-1]\n    PCs = PCs[:,:-1]\n    return addrs[:limit], PCs[:limit], deltas[:limit]\n","execution_count":7,"outputs":[]},{"metadata":{"id":"6rhgiaqZtgOO","trusted":true},"cell_type":"code","source":"addrs, PCs, deltas = parse_data()","execution_count":8,"outputs":[{"output_type":"stream","text":"                                               ADDRS  \\\n0  44977833404864,44977833405056,44977833406528,4...   \n1  44977833405056,44977833406528,44977833399552,4...   \n2  44977833399616,44977833405120,44977833399680,4...   \n3  44977833399744,44977833399808,44977833399872,4...   \n4  44977833399808,44977833399872,44977833404992,4...   \n\n                                                 PCS  \n0  4203619,4203626,4203647,4203781,4203840,420372...  \n1  4203626,4203647,4203781,4203840,4203727,420390...  \n2  4203840,4203727,4203909,4203781,4203817,420397...  \n3  4203970,4204032,4204098,4204088,4204160,420422...  \n4  4204032,4204098,4204088,4204160,4204228,420422...  \n(139998, 11)\n","name":"stdout"}]},{"metadata":{"id":"_FBwLqCQjzfY","outputId":"bb55992d-9451-423b-e233-ce3de2c02ef4","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport os\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\ndef create_dataset(addrs, PCs, deltas, maxlen=10, num_classes=3000):\n    def get_cluster_id(center1, center2, center3, point):\n        arr = np.array([abs(center1-point), abs(center2-point), abs(center3-point)])\n        return np.argmin(arr)\n    \n    scaler = MinMaxScaler((0, 1))\n\n    del_freq = Counter(deltas)\n    \n    plt.figure(1)\n    plt.plot([i for i in range(len(deltas))], deltas, 'k.')\n    plt.show()\n    \n    max10000 = del_freq.most_common(num_classes)\n    print(\">>>>>>>\",max10000)\n    del_list = {}\n    total_cnt = 0.\n    inv_del_list = {}\n\n    for idx, delta in enumerate(max10000):\n        del_list[int(delta[0])] = idx\n        inv_del_list[idx] = int(delta[0])\n        total_cnt += delta[1]\n\n    ip1 = 4195632.0\n    ip2 = 8208480.0\n\n    addr11 = 96935917361984.0\n    addr12 = 195743444536640.0\n\n    addr21 = 5610901135424.0\n    addr22 = 80904477544064.0\n\n    addr31 = 222418542097984.0\n    addr32 = 279264050879424.0\n\n    center1 = 1.61729982e+14\n    center2 = 3.12041036e+13\n    center3 = 2.53453964e+14\n\n    IPs = []\n    Addrs = []\n    Clusters = []\n    deltas_new = []\n    for i in range(addrs.shape[0]):\n        if deltas[i] in del_list:\n            IPs.append([(ip-ip1)/(ip2-ip1) for ip in PCs[i]])\n            cluster_ids = [get_cluster_id(center1, center2, center3, addr) for addr in addrs[i]]\n            Clusters.append(cluster_ids)\n            addrs_new = addrs[i]\n            addrs_new[cluster_ids==0] = (addrs_new[cluster_ids==0] - addr11)/(addr12-addr11)\n            addrs_new[cluster_ids==1] = (addrs_new[cluster_ids==1] - addr21)/(addr22-addr21)\n            addrs_new[cluster_ids==2] = (addrs_new[cluster_ids==2] - addr31)/(addr32-addr31) \n            Addrs.append(addrs_new)\n            deltas_new.append(deltas[i])\n    \n    with open('idx_delta_map.json', 'w') as f:\n        json.dump(inv_del_list, f)\n    with open('delta_idx_map.json', 'w') as f:\n        json.dump(del_list, f)\n    print(\"Proportion of data in top {}: {}\".format(num_classes, total_cnt / len(deltas)))\n\n    X = np.concatenate([np.array(IPs).reshape(-1, maxlen, 1), np.array(Clusters).reshape(-1, maxlen, 1), np.array(Addrs).reshape(-1, maxlen, 1)], axis=2)\n\n    y = [del_list[delta] for delta in deltas_new]\n    y = to_categorical(y, num_classes=num_classes)\n    return np.array(X).reshape(-1, maxlen, 3), np.array(y)","execution_count":10,"outputs":[]},{"metadata":{"id":"J1cVszEAk2Wu","outputId":"e07e976d-d6da-4866-c907-185c661db151","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport keras\n\nclass MyCustomCallback(keras.callbacks.Callback):\n    def __init__(self, test_data, k=10):\n        self.X_test, self.y_test = test_data\n        self.k = k\n\n    def on_train_batch_end(self, batch, logs=None):\n        if (batch+1)%300!=0:\n            return\n        y_test_pred = self.model.predict(self.X_test)\n        topk = y_test_pred.argsort()[:, -self.k:]\n        acc = 0.\n        for i in range(self.y_test.shape[0]):\n            if np.argmax(self.y_test[i]) in topk[i]:\n                acc += 1.\n        print(\"ACC: \", acc / float(self.y_test.shape[0]))\n\nX, y = create_dataset(addrs, PCs, deltas, num_classes=10, maxlen=10)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1234)\n\nprint(\"Training X & y: \", X_train.shape, y_train.shape)\nprint(\"Validation X & y: \", X_test.shape, y_test.shape)\n","execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","text":">>>>>>> [(-64, 10212), (64, 10047), (-128, 9893), (192, 9819), (256, 9591), (128, 438)]\nProportion of data in top 10: 1.0\nTraining X & y:  (45000, 10, 3) (45000, 10)\nValidation X & y:  (5000, 10, 3) (5000, 10)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lstm_model(X_train, y_train, X_test, y_test, rnn_units=32, batch_size=64, maxlen=10, num_labels=3, num_classes=3000, epochs=3, toplot=False):\n    input_layer1 = keras.layers.Input(shape=(maxlen, 3, ), name='input1')\n\n    #LSTM Layer 1 with Dropout\n    lstm_layer1 = keras.layers.LSTM(rnn_units, return_sequences=True)(input_layer1)\n    lstm_layer1 = keras.layers.Dropout(0.2)(lstm_layer1)\n\n    #LSTM Layer 2 with Dropout\n#     lstm_layer2 = keras.layers.LSTM(rnn_units)(lstm_layer1)\n    lstm_layer2 = keras.layers.LSTM(rnn_units, return_sequences=True)(lstm_layer1)\n    lstm_layer2 = keras.layers.Dropout(0.2)(lstm_layer2)\n\n    self_attn1 = SeqSelfAttention(\n        attention_width=5,\n        attention_activation='sigmoid',\n        history_only=False,\n        name='SelfAttention1',\n        attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL\n    )(lstm_layer2)\n\n    self_attn1 = keras.layers.GlobalAveragePooling1D()(self_attn1)\n    lstm_out = keras.layers.Lambda(lambda t: t[:,-1])(lstm_layer2)\n    penultimate = keras.layers.Concatenate()([lstm_out, self_attn1])\n    #Output Layer\n    prediction = keras.layers.Dense(num_classes, activation='softmax')(penultimate)\n\n    #Model Inputs and outputs\n    model = keras.models.Model(inputs=input_layer1, outputs=prediction)\n    #Use Categorical Loss and Accuracy with Adam Optimizer\n    model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n    print(model.summary())\n\n    #Fit the model to the data\n    history = model.fit(X, y, batch_size=batch_size, epochs=epochs, shuffle=False, callbacks=[MyCustomCallback((X_test, y_test), k=4)])\n\n    #Plot the loss curves\n    if toplot:\n        plt.plot(history.history['loss'])\n        plt.title('model loss')\n        plt.ylabel('loss')\n        plt.xlabel('epoch')\n        plt.legend(['train'], loc='upper left')\n        plt.show()\n\n    return model","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Use TPU Strategy\nwith tpu_strategy.scope():\n    model = get_lstm_model(X_train, y_train, X_test, y_test, rnn_units=64, batch_size=64, num_classes=10, maxlen=10, epochs=4, toplot=True)","execution_count":13,"outputs":[{"output_type":"stream","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput1 (InputLayer)             (None, 10, 3)        0                                            \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   (None, 10, 64)       17408       input1[0][0]                     \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 10, 64)       0           lstm_1[0][0]                     \n__________________________________________________________________________________________________\nlstm_2 (LSTM)                   (None, 10, 64)       33024       dropout_1[0][0]                  \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 10, 64)       0           lstm_2[0][0]                     \n__________________________________________________________________________________________________\nSelfAttention1 (SeqSelfAttentio (None, 10, 64)       4097        dropout_2[0][0]                  \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 64)           0           dropout_2[0][0]                  \n__________________________________________________________________________________________________\nglobal_average_pooling1d_1 (Glo (None, 64)           0           SelfAttention1[0][0]             \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 128)          0           lambda_1[0][0]                   \n                                                                 global_average_pooling1d_1[0][0] \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 10)           1290        concatenate_1[0][0]              \n==================================================================================================\nTotal params: 55,819\nTrainable params: 55,819\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\nEpoch 1/4\n19136/50000 [==========>...................] - ETA: 18s - loss: 1.6889 - categorical_accuracy: 0.1999ACC:  0.9904\n38336/50000 [======================>.......] - ETA: 7s - loss: 1.6724 - categorical_accuracy: 0.1984ACC:  0.9904\n43904/50000 [=========================>....] - ETA: 3s - loss: 1.6693 - categorical_accuracy: 0.1985","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-895228b71e38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Use TPU Strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtpu_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-cd963d23e85f>\u001b[0m in \u001b[0;36mget_lstm_model\u001b[0;34m(X_train, y_train, X_test, y_test, rnn_units, batch_size, maxlen, num_labels, num_classes, epochs, toplot)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#Fit the model to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMyCustomCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#Plot the loss curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m         expand_composites=True)\n\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3798\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3799\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3800\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3801\u001b[0m         expand_composites=True)\n\u001b[1;32m   3802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"o6vKuSlgFqSx","trusted":true},"cell_type":"code","source":"with open('model_for_cpp_mcf_self_attn.json', 'w') as fout:\n    fout.write(model.to_json())\nmodel.save_weights('model_for_cpp_weights_mcf_self_attn.h5', overwrite=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\nfrom IPython.display import FileLink\nFileLink(r'delta_idx_map.json')","execution_count":null,"outputs":[]},{"metadata":{"id":"ydKtMw8rXzYi","outputId":"fd78d685-1282-4708-a6a6-d4183eb6ed96","trusted":false},"cell_type":"code","source":"# import numpy as np\n# import keras\n# import json\n# from keras_self_attention import SeqSelfAttention\n\n\n# def initialize_idx_to_delta(ROOT_DIR=\"./\"):\n#   idx_to_delta = None\n#   with open(ROOT_DIR + 'delta_idx_map.json') as json_file:\n#     idx_to_delta = json.load(json_file)\n#   return idx_to_delta\n\n# def initialize_model(ROOT_DIR=\"./\"):\n#   f = open(ROOT_DIR + \"model_for_cpp_self_attn.json\")\n#   model = keras.models.model_from_json(f.read(), custom_objects={'SeqSelfAttention': SeqSelfAttention})\n#   # tf.keras.models.model_from_json()\n#   f.close()\n#   model.load_weights(ROOT_DIR + \"model_for_cpp_self_attn_weights.h5\")\n#   model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n#   return model\n\n# def prefetch_predict(lastNData) -> int:\n#   N = 20\n#   if len(lastNData) < 2*N+3:\n#     return -1\n\n#   lastNPCs = lastNData[:N]\n#   lastNAddrs = lastNData[N:2*N]\n#   topk = lastNData[2*N]\n#   idx_to_delta = lastNData[2*N+1]\n#   model = lastNData[2*N+2]\n\n#   ip1 = 4195632.0\n#   ip2 = 8208480.0\n\n#   addr11 = 96935917361984.0\n#   addr12 = 195743444536640.0\n\n#   addr21 = 5610901135424.0\n#   addr22 = 80904477544064.0\n\n#   addr31 = 222418542097984.0\n#   addr32 = 279264050879424.0\n\n#   center1 = 1.61729982e+14\n#   center2 = 3.12041036e+13\n#   center3 = 2.53453964e+14\n\n#   ips = np.array(lastNPCs)\n#   ips = [(ip-ip1)/(ip2-ip1) for ip in ips]\n\n#   def get_cluster_id(center1, center2, center3, point):\n#     arr = np.array([abs(center1-point), abs(center2-point), abs(center3-point)])\n#     return np.argmin(arr)\n\n#   addrs = np.array(lastNAddrs)\n#   cluster_ids = [get_cluster_id(center1, center2, center3, addr) for addr in addrs]\n\n#   addrs[cluster_ids==0] = (addrs[cluster_ids==0] - addr11)/(addr12-addr11)\n#   addrs[cluster_ids==1] = (addrs[cluster_ids==1] - addr21)/(addr22-addr21)\n#   addrs[cluster_ids==2] = (addrs[cluster_ids==2] - addr31)/(addr32-addr31)\n\n#   X = np.array([list(xx) for xx in zip(ips, cluster_ids, addrs)])\n#   X = X.reshape(1, N, 3)\n\n#   y_pred = model.predict(X)\n#   topkidxs = y_pred.argsort()[:, -topk:][0]\n\n#   return [idx_to_delta[str(idx)] for idx in topkidxs]\n  \n# # idx_to_delta = initialize_idx_to_delta(ROOT_DIR)\n# # model1 = initialize_model(ROOT_DIR)\n# # print(prefetch_predict([0.58037982, 0.58037907, 0.58037982, 0.58037982, 0.58038406, 0.58037982, 0.58037982, 0.58037907, 0.58037982, 0.58037907, 0.58037982, 0.58038406, 0.58037982, 0.58037982, 0.58037982, 0.58038406, 0.58037907, 0.58037982, 0.58037907, 0.58037907, 0.56376003, 0.56376003, 0.56376003, 0.56376001, 0.56376001, 0.56376002, 0.25783423, 0.56376002, 0.25783423, 0.25783423, 0.25783423, 0.56376003, 0.57493763, 0.56376003, 0.56376002, 0.56376002, 0.22437261, 0.56376002, 0.88635157, 0.88635157, 10, idx_to_delta, model1]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}